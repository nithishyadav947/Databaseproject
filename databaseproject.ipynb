{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3954dec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please list the primary key column(s), separated by commas: OrderID, CustomerID, DrinkID, FoodID\n",
      "Enter Functional Dependencies in 'X,Y -> Z,W' format (type 'end' when done):\n",
      "OrderID -> CustomerID\n",
      "end\n",
      "Enter the desired highest normal form (1: 1NF, 2: 2NF, 3: 3NF, B: BCNF, 4: 4NF, 5: 5NF): 4\n",
      "Specify Multi-Valued Dependencies in 'A ->> B' format (type 'end' when done):\n",
      "OrderID ->> DrinkID\n",
      "done\n",
      "Incorrect format. Use 'A ->> B'.\n",
      "end\n",
      "CREATE TABLE Table_1NF (\n",
      "  OrderID INT,\n",
      "  Date VARCHAR(255),\n",
      "  PromocodeUsed VARCHAR(255),\n",
      "  TotalCost VARCHAR(255),\n",
      "  TotalDrinkCost VARCHAR(255),\n",
      "  TotalFoodCost VARCHAR(255),\n",
      "  CustomerID INT,\n",
      "  CustomerName VARCHAR(255),\n",
      "  DrinkID INT,\n",
      "  DrinkName VARCHAR(255),\n",
      "  DrinkSize VARCHAR(255),\n",
      "  DrinkQuantity INT,\n",
      "  Milk VARCHAR(255),\n",
      "  DrinkIngredient VARCHAR(255),\n",
      "  DrinkAllergen VARCHAR(255),\n",
      "  FoodID INT,\n",
      "  FoodName VARCHAR(255),\n",
      "  FoodQuantity INT,\n",
      "  FoodIngredient VARCHAR(255),\n",
      "  FoodAllergen VARCHAR(255),\n",
      "  PRIMARY KEY (OrderID, CustomerID, DrinkID, FoodID)\n",
      ");\n",
      "CREATE TABLE Table_4NF_1 (\n",
      "  OrderID INT,\n",
      "  Date VARCHAR(255),\n",
      "  PromocodeUsed VARCHAR(255),\n",
      "  TotalCost VARCHAR(255),\n",
      "  TotalDrinkCost VARCHAR(255),\n",
      "  TotalFoodCost VARCHAR(255),\n",
      "  CustomerID INT,\n",
      "  CustomerName VARCHAR(255),\n",
      "  DrinkName VARCHAR(255),\n",
      "  DrinkSize VARCHAR(255),\n",
      "  DrinkQuantity INT,\n",
      "  Milk VARCHAR(255),\n",
      "  DrinkIngredient VARCHAR(255),\n",
      "  DrinkAllergen VARCHAR(255),\n",
      "  FoodID INT,\n",
      "  FoodName VARCHAR(255),\n",
      "  FoodQuantity INT,\n",
      "  FoodIngredient VARCHAR(255),\n",
      "  FoodAllergen VARCHAR(255),\n",
      "  PRIMARY KEY (OrderID, CustomerID, DrinkID, FoodID)\n",
      ");\n",
      "CREATE TABLE Table_4NF_2 (\n",
      "  OrderID INT,\n",
      "  DrinkID INT,\n",
      "  PRIMARY KEY (OrderID, DrinkID)\n",
      ");\n",
      "Normalization results saved to C:/Users/saiki/OneDrive/Desktop/output1.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "# Load the input file\n",
    "data_file_path = 'C:/Users/saiki/OneDrive/Desktop/Sampledata.csv'\n",
    "data = pd.read_csv(data_file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = 'C:/Users/saiki/OneDrive/Desktop/output1.txt'\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "\n",
    "    # Prompt for primary keys\n",
    "    primary_key_columns = input(\"Please list the primary key column(s), separated by commas: \").split(',')\n",
    "    primary_key_columns = [col.strip() for col in primary_key_columns]\n",
    "\n",
    "    # Prompt for functional dependencies\n",
    "    func_deps = {}\n",
    "    print(\"Enter Functional Dependencies in 'X,Y -> Z,W' format (type 'end' when done):\")\n",
    "    while True:\n",
    "        fd_input = input()\n",
    "        if fd_input.lower() == 'end':\n",
    "            break\n",
    "        try:\n",
    "            lhs, rhs = fd_input.split(\"->\")\n",
    "            lhs_attrs = [attr.strip() for attr in lhs.split(',')]\n",
    "            rhs_attrs = [attr.strip() for attr in rhs.split(',')]\n",
    "            func_deps[tuple(lhs_attrs)] = rhs_attrs\n",
    "            output_file.write(f\"Functional Dependency: {lhs} -> {rhs}\\n\")\n",
    "        except ValueError:\n",
    "            print(\"Incorrect format. Use 'X,Y -> Z,W'.\")\n",
    "\n",
    "    # Get the target normal form level\n",
    "    target_form = input(\"Enter the desired highest normal form (1: 1NF, 2: 2NF, 3: 3NF, B: BCNF, 4: 4NF, 5: 5NF): \")\n",
    "    if target_form in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
    "        target_form = int(target_form)\n",
    "\n",
    "    # Prompt for multi-valued dependencies if target form is 4NF or higher\n",
    "    mvd_dependencies = {}\n",
    "    if target_form >= 4:\n",
    "        print(\"Specify Multi-Valued Dependencies in 'A ->> B' format (type 'end' when done):\")\n",
    "        while True:\n",
    "            mvd_input = input()\n",
    "            if mvd_input.lower() == 'end':\n",
    "                break\n",
    "            try:\n",
    "                lhs, rhs = mvd_input.split(\"->>\")\n",
    "                lhs, rhs = lhs.strip(), rhs.strip()\n",
    "                if lhs in mvd_dependencies:\n",
    "                    mvd_dependencies[lhs].append(rhs)\n",
    "                else:\n",
    "                    mvd_dependencies[lhs] = [rhs]\n",
    "                output_file.write(f\"Multi-Valued Dependency: {lhs} ->> {rhs}\\n\")\n",
    "            except ValueError:\n",
    "                print(\"Incorrect format. Use 'A ->> B'.\")\n",
    "\n",
    "    # Prompt for join dependencies if target form is 5NF\n",
    "    jd_dependencies = []\n",
    "    if target_form == 5:\n",
    "        print(\"Specify Join Dependencies in 'X,Y' format (type 'end' when done):\")\n",
    "        while True:\n",
    "            jd_input = input()\n",
    "            if jd_input.lower() == 'end':\n",
    "                break\n",
    "            jd_attrs = [attr.strip() for attr in jd_input.split(',')]\n",
    "            jd_dependencies.append(jd_attrs)\n",
    "            output_file.write(f\"Join Dependency: {', '.join(jd_attrs)}\\n\")\n",
    "\n",
    "    # Function to enforce 1NF by handling non-atomic attributes\n",
    "    def enforce_1nf(df):\n",
    "        atomic_cols = []\n",
    "        for col in df.columns:\n",
    "            if df[col].apply(lambda x: isinstance(x, list)).any():\n",
    "                atomic_cols.append(col)\n",
    "                df = df.explode(col)\n",
    "        return df, atomic_cols\n",
    "\n",
    "    # Function to check 2NF\n",
    "    def check_2nf(df, pk_columns, deps):\n",
    "        non_pk_columns = [col for col in df.columns if col not in pk_columns]\n",
    "        for lhs, rhs in deps.items():\n",
    "            if set(lhs).issubset(pk_columns) and any(attr in non_pk_columns for attr in rhs):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Function to check 3NF\n",
    "    def check_3nf(df, pk_columns, deps):\n",
    "        for lhs, rhs in deps.items():\n",
    "            if set(lhs) != set(pk_columns) and not set(rhs).issubset(pk_columns):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Function to check BCNF\n",
    "    def check_bcnf(df, pk_columns, deps):\n",
    "        for lhs, rhs in deps.items():\n",
    "            if not set(lhs).issubset(pk_columns):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    # Function to apply 4NF with multi-valued dependencies\n",
    "    def apply_4nf(df, mv_deps):\n",
    "        decomposed_tables = []\n",
    "        remaining_columns = list(df.columns)\n",
    "\n",
    "        for lhs, rhs_list in mv_deps.items():\n",
    "            for rhs in rhs_list:\n",
    "                decomposed_table = df[[lhs, rhs]].drop_duplicates()\n",
    "                decomposed_tables.append((decomposed_table, [lhs, rhs]))\n",
    "                if rhs in remaining_columns:\n",
    "                    remaining_columns.remove(rhs)\n",
    "                output_file.write(f\"4NF Decomposition: Created table with {lhs} ->> {rhs}\\n\")\n",
    "\n",
    "        main_table = df[remaining_columns].drop_duplicates()\n",
    "        return [(main_table, primary_key_columns)] + decomposed_tables\n",
    "\n",
    "    # Function to apply 5NF with join dependencies\n",
    "    def apply_5nf(df, jd_deps):\n",
    "        decomposed_tables = []\n",
    "\n",
    "        for jd in jd_deps:\n",
    "            if set(jd).issubset(df.columns):\n",
    "                decomposed_table = df[jd].drop_duplicates()\n",
    "                decomposed_tables.append((decomposed_table, jd))\n",
    "                output_file.write(f\"5NF Decomposition: Created table for JD ({', '.join(jd)})\\n\")\n",
    "\n",
    "        if not decomposed_tables:\n",
    "            output_file.write(\"No further 5NF decomposition required.\\n\")\n",
    "        return [(df, primary_key_columns)] + decomposed_tables\n",
    "\n",
    "    # SQL Query Generator and Schema Representation\n",
    "    def generate_sql_schema(table_name, df, pk_columns):\n",
    "        sql_query = f\"CREATE TABLE {table_name} (\\n\"\n",
    "        schema_info = f\"Table: {table_name}\\nAttributes:\\n\"\n",
    "\n",
    "        for col, dtype in zip(df.columns, df.dtypes):\n",
    "            col_type = 'INT' if 'int' in str(dtype) else 'VARCHAR(255)'\n",
    "            sql_query += f\"  {col} {col_type},\\n\"\n",
    "            schema_info += f\"  - {col} ({col_type})\\n\"\n",
    "\n",
    "        pk_str = \", \".join(pk_columns)\n",
    "        sql_query += f\"  PRIMARY KEY ({pk_str})\\n);\"\n",
    "        schema_info += f\"Primary Key(s): {pk_str}\\n\\n\"\n",
    "\n",
    "        print(sql_query)\n",
    "        output_file.write(sql_query + \"\\n\\n\" + schema_info)\n",
    "\n",
    "    # Main Normalization Process\n",
    "    def normalize_data(df, pk_columns, f_deps, mv_deps, target_form, jd_deps=[]):\n",
    "        df, atomic_cols = enforce_1nf(df)\n",
    "        output_file.write(\"Applied 1NF\\n\" if not atomic_cols else f\"1NF: Converted non-atomic columns {atomic_cols}\\n\")\n",
    "        generate_sql_schema('Table_1NF', df, pk_columns)\n",
    "\n",
    "        current_nf = 1\n",
    "        if target_form >= 2 and check_2nf(df, pk_columns, f_deps):\n",
    "            output_file.write(\"2NF validation successful.\\n\")\n",
    "            current_nf = 2\n",
    "        else:\n",
    "            output_file.write(\"2NF decomposition needed.\\n\")\n",
    "\n",
    "        if target_form >= 3 and check_3nf(df, pk_columns, f_deps):\n",
    "            output_file.write(\"3NF validation successful.\\n\")\n",
    "            current_nf = 3\n",
    "        else:\n",
    "            output_file.write(\"3NF decomposition needed.\\n\")\n",
    "\n",
    "        if target_form >= 4 and check_bcnf(df, pk_columns, f_deps):\n",
    "            output_file.write(\"BCNF validation successful.\\n\")\n",
    "            current_nf = \"BCNF\"\n",
    "        else:\n",
    "            output_file.write(\"BCNF decomposition needed.\\n\")\n",
    "\n",
    "        decomposed_tables = [(df, pk_columns)]\n",
    "        if target_form >= 4:\n",
    "            decomposed_tables = apply_4nf(df, mv_deps)\n",
    "            for i, (table, keys) in enumerate(decomposed_tables, start=1):\n",
    "                table_name = f\"Table_4NF_{i}\"\n",
    "                generate_sql_schema(table_name, table, keys)\n",
    "            current_nf = 4 if current_nf != \"BCNF\" else current_nf\n",
    "\n",
    "        if target_form == 5:\n",
    "            decomposed_tables = apply_5nf(df, jd_deps)\n",
    "            for i, (table, keys) in enumerate(decomposed_tables, start=1):\n",
    "                table_name = f\"Table_5NF_{i}\"\n",
    "                generate_sql_schema(table_name, table, keys)\n",
    "\n",
    "        output_file.write(f\"The highest normal form achieved: {current_nf}\\n\")\n",
    "\n",
    "    # Execute the normalization\n",
    "    normalize_data(data, primary_key_columns, func_deps, mvd_dependencies, target_form, jd_dependencies)\n",
    "\n",
    "print(f\"Normalization results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab1a375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
